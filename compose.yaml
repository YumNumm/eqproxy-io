services:
  eqproxy-io:
    build:
      context: .
      target: eqproxy-io
    env_file:
      - .env
    environment:
      - TZ=Asia/Tokyo
      - PORT=4000
    restart: always
    ports:
      # ws.api.eqmonitor.app
      - 4000:4000
      # Prometheus metrics
      - 4002:4002
    logging:
      driver: json-file
      options:
        max-size: 1m
        max-file: "3"

  dmdata-proxy:
    build:
      context: .
      target: dmdata-proxy
    env_file:
      - ./service/dmdata-proxy/.env
    environment:
      - TZ=Asia/Tokyo
      - WEBSOCKET_PORT=4020
      - NEW_RELIC_APP_NAME=dmdata-proxy
    restart: always
    ports:
      - 4020:4020
    logging:
      driver: json-file
      options:
        max-size: 1m
        max-file: "3"
    healthcheck:
      test: ["CMD", "curl", "http://localhost:4020/health"]
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 30s

  supabase-proxy:
    build: ./service/supabase-proxy
    env_file:
      - ./service/supabase-proxy/.env
    environment:
      - TZ=Asia/Tokyo
      - PORT=4010
    restart: always
    ports:
      - 4010:4010
    logging:
      driver: json-file
      options:
        max-size: 1m
        max-file: "3"
    healthcheck:
      test: ["CMD", "curl", "http://localhost:4010/health"]
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 30s

  telegram-proxy-server:
    build:
      context: .
      dockerfile: ./server/telegram-proxy-server/Dockerfile
    env_file:
      - ./server/telegram-proxy-server/.env
    environment:
      - TZ=Asia/Tokyo
      - PORT=4030
      - SUPABASE_PROXY_URL=ws://supabase-proxy:4010/ws
      - DMDATA_PROXY_URL=ws://dmdata-proxy:4020/ws
    restart: always
    depends_on:
      supabase-proxy:
        condition: service_healthy
      dmdata-proxy:
        condition: service_healthy
    ports:
      - 4030:4030
    logging:
      driver: json-file
      options:
        max-size: 1m
        max-file: "3"
    healthcheck:
      test: ["CMD", "curl", "http://localhost:4030/health"]
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 30s

  db:
    container_name: supabase-db
    build: ./db
    healthcheck:
      test: pg_isready -U postgres -h localhost
      interval: 5s
      timeout: 5s
      retries: 10
    command:
      - postgres
      - -c
      - config_file=/etc/postgresql/postgresql.conf
      - -c
      - log_min_messages=error # prevents Realtime polling queries from appearing in logs
    restart: unless-stopped
    ports:
      # Pass down internal port because it's set dynamically by other services
      - ${POSTGRES_PORT}:${POSTGRES_PORT}
    environment:
      POSTGRES_HOST: /var/run/postgresql
      PGPORT: ${POSTGRES_PORT}
      POSTGRES_PORT: ${POSTGRES_PORT}
      PGPASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATABASE: ${POSTGRES_DB}
      POSTGRES_DB: ${POSTGRES_DB}
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXP: ${JWT_EXPIRY}
      POSTGRES_INITDB_ARGS: --locale=ja_JP.utf8
      TZ: Asia/Tokyo
    volumes:
      # Must be superuser to alter reserved role
      - ./db/roles.sql:/docker-entrypoint-initdb.d/init-scripts/99-roles.sql:Z
      # PGDATA directory is persisted between restarts
      - ./db/data:/var/lib/postgresql/data:Z
      - ./db/init/data.sql:/docker-entrypoint-initdb.d/migrations/99-data.sql:Z
      # Use named volume to persist pgsodium decryption key between restarts
      - db-config:/etc/postgresql-custom
      - ./db/postgresql.conf:/etc/postgresql/postgresql.conf:Z

  postgres-exporter:
    container_name: postgres-exporter
    image: quay.io/prometheuscommunity/postgres-exporter
    hostname: postgres-exporter
    env_file:
      - .env
    ports:
      - 9187:9187

  rabbitmq:
    container_name: rabbitmq
    image: rabbitmq:3.12-management-alpine
    environment:
      RABBITMQ_ERLANG_COOKIE: "SWQOKODSQALRPCLNMEQG"
      RABBITMQ_DEFAULT_USER: "rabbitmq"
      RABBITMQ_DEFAULT_PASS: "rabbitmq"
      RABBITMQ_DEFAULT_VHOST: "/"
    healthcheck:
      test: rabbitmq-diagnostics check_port_connectivity
      interval: 1s
      timeout: 3s
      retries: 30
    cap_add:
      - ALL
    ports:
      - 15672:15672
      - 15692:15692
      - 5672:5672
    labels:
      NAME: "rabbitmq1"
    volumes:
      - ./rabbitmq:/etc/rabbitmq:Z

  notification-producer:
    container_name: notification-producer
    build:
      context: .
      target: notification-producer
    environment:
      - TZ=Asia/Tokyo
      - RABBITMQ_HOST=rabbitmq
    env_file:
      - .env
    restart: always
    depends_on:
      rabbitmq:
        condition: service_healthy
    logging:
      driver: json-file
      options:
        max-size: 1m
        max-file: "3"

  notification-worker:
    container_name: notification-worker
    build:
      context: .
      target: notification-worker
    environment:
      - TZ=Asia/Tokyo
      - RABBITMQ_HOST=rabbitmq
      - GOOGLE_APPLICATION_CREDENTIALS=/app/credentials.json
    env_file:
      - .env
    restart: always
    volumes:
      - ./service/notification-worker/credentials.json:/app/credentials.json:ro
    depends_on:
      rabbitmq:
        condition: service_healthy
    logging:
      driver: json-file
      options:
        max-size: 1m
        max-file: "3"

  fcm-token-verify:
    build:
      context: .
      target: fcm-token-verify
    environment:
      - TZ=Asia/Tokyo
      - PORT=3000
    env_file:
      - .env
    ports:
      - 8020:3000
    volumes:
      - ./server/fcm-token-verify/credentials.json:/prod/server/fcm-token-verify/credentials.json:ro

  read:
    image: grafana/loki:3.0.0
    command: "-config.file=/etc/loki/config.yaml -target=read"
    ports:
      - 3101:3100
      - 7946
      - 9095
    volumes:
      - ./loki-config.yaml:/etc/loki/config.yaml
    depends_on:
      - minio
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: &loki-dns
      loki:
        aliases:
          - loki

  write:
    image: grafana/loki:3.0.0
    command: "-config.file=/etc/loki/config.yaml -target=write"
    ports:
      - 3102:3100
      - 7946
      - 9095
    volumes:
      - ./loki-config.yaml:/etc/loki/config.yaml
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - minio
    networks:
      <<: *loki-dns

  alloy:
    image: grafana/alloy-dev:latest
    volumes:
      - ./alloy-local-config.yaml:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: run --server.http.listen-addr=0.0.0.0:12345 --storage.path=/var/lib/alloy/data /etc/alloy/config.alloy
    ports:
      - 12345:12345
    depends_on:
      - gateway
    networks:
      - loki

  backend:
    image: grafana/loki:3.0.0
    volumes:
      - ./loki-config.yaml:/etc/loki/config.yaml
    ports:
      - "3100"
      - "7946"
    command: "-config.file=/etc/loki/config.yaml -target=backend -legacy-read-mode=false"
    depends_on:
      - gateway

  gateway:
    image: nginx:latest
    depends_on:
      - read
      - write
    entrypoint:
      - sh
      - -euc
      - |
        cat <<EOF > /etc/nginx/nginx.conf
        user  nginx;
        worker_processes  5;  ## Default: 1

        events {
          worker_connections   1000;
        }

        http {
          resolver 127.0.0.11;

          server {
            listen             3100;

            location = / {
              return 200 'OK';
              auth_basic off;
            }

            location = /api/prom/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /api/prom/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /api/prom/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }

            location = /loki/api/v1/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /loki/api/v1/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /loki/api/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }
          }
        }
        EOF
        /docker-entrypoint.sh nginx -g "daemon off;"
    ports:
      - "3100:3100"
    healthcheck:
      test: ["CMD", "service", "nginx", "status"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  db-config:
